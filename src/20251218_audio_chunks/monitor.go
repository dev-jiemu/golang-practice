package main

import (
	"context"
	"log"
	"runtime"
	"strings"
	"sync"
	"time"
)

// ResourceMonitor : ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ëª¨ë‹ˆí„°ë§
type ResourceMonitor struct {
	mu                sync.Mutex
	startTime         time.Time
	activeWorkers     int
	maxActiveWorkers  int
	totalChunks       int
	processedChunks   int
	failedChunks      int
	cpuSamples        []float64
	memorySamplesMB   []float64
	workerStartTimes  map[int]time.Time
	workerDurations   []time.Duration
	chunkProcessTimes []time.Duration
}

func NewResourceMonitor() *ResourceMonitor {
	return &ResourceMonitor{
		startTime:         time.Now(),
		cpuSamples:        make([]float64, 0),
		memorySamplesMB:   make([]float64, 0),
		workerStartTimes:  make(map[int]time.Time),
		workerDurations:   make([]time.Duration, 0),
		chunkProcessTimes: make([]time.Duration, 0),
	}
}

// StartMonitoring : ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì£¼ê¸°ì ìœ¼ë¡œ ì‹œìŠ¤í…œ ë¦¬ì†ŒìŠ¤ ìˆ˜ì§‘
func (m *ResourceMonitor) StartMonitoring(ctx context.Context, interval time.Duration) {
	ticker := time.NewTicker(interval)
	go func() {
		defer ticker.Stop()
		for {
			select {
			case <-ctx.Done():
				return
			case <-ticker.C:
				m.collectResourceStats()
			}
		}
	}()
}

// collectResourceStats : í˜„ì¬ ë©”ëª¨ë¦¬ ë° ê³ ë£¨í‹´ ìˆ˜ ìˆ˜ì§‘
func (m *ResourceMonitor) collectResourceStats() {
	m.mu.Lock()
	defer m.mu.Unlock()

	var mem runtime.MemStats
	runtime.ReadMemStats(&mem)

	// ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)
	memoryMB := float64(mem.Alloc) / 1024 / 1024
	m.memorySamplesMB = append(m.memorySamplesMB, memoryMB)

	// ê³ ë£¨í‹´ ìˆ˜ëŠ” CPU ì‚¬ìš©ì˜ ê°„ì ‘ ì§€í‘œ
	numGoroutines := float64(runtime.NumGoroutine())
	m.cpuSamples = append(m.cpuSamples, numGoroutines)
}

// WorkerStart : ì›Œì»¤ ì‹œì‘ ê¸°ë¡
func (m *ResourceMonitor) WorkerStart(workerID int) {
	m.mu.Lock()
	defer m.mu.Unlock()

	m.activeWorkers++
	if m.activeWorkers > m.maxActiveWorkers {
		m.maxActiveWorkers = m.activeWorkers
	}
	m.workerStartTimes[workerID] = time.Now()
}

// WorkerEnd : ì›Œì»¤ ì¢…ë£Œ ê¸°ë¡
func (m *ResourceMonitor) WorkerEnd(workerID int) {
	m.mu.Lock()
	defer m.mu.Unlock()

	m.activeWorkers--
	if startTime, ok := m.workerStartTimes[workerID]; ok {
		duration := time.Since(startTime)
		m.workerDurations = append(m.workerDurations, duration)
		delete(m.workerStartTimes, workerID)
	}
}

// ChunkProcessed : ì²­í¬ ì²˜ë¦¬ ì™„ë£Œ ê¸°ë¡
func (m *ResourceMonitor) ChunkProcessed(success bool, duration time.Duration) {
	m.mu.Lock()
	defer m.mu.Unlock()

	m.processedChunks++
	if !success {
		m.failedChunks++
	}
	m.chunkProcessTimes = append(m.chunkProcessTimes, duration)
}

// SetTotalChunks : ì „ì²´ ì²­í¬ ìˆ˜ ì„¤ì •
func (m *ResourceMonitor) SetTotalChunks(total int) {
	m.mu.Lock()
	defer m.mu.Unlock()
	m.totalChunks = total
}

// PrintSummary : ìµœì¢… ìš”ì•½ ì •ë³´ ì¶œë ¥
func (m *ResourceMonitor) PrintSummary() {
	m.mu.Lock()
	defer m.mu.Unlock()

	totalDuration := time.Since(m.startTime)

	log.Println(strings.Repeat("=", 60))
	log.Println("ğŸ“Š Resource Usage Summary")
	log.Println(strings.Repeat("=", 60))

	// ì‹œê°„ ì •ë³´
	log.Printf("â±ï¸  Total Processing Time: %s\n", totalDuration.Round(time.Millisecond))

	// ì²­í¬ ì²˜ë¦¬ ì •ë³´
	log.Printf("ğŸ“¦ Total Chunks: %d\n", m.totalChunks)
	log.Printf("âœ… Successfully Processed: %d\n", m.processedChunks-m.failedChunks)
	log.Printf("âŒ Failed: %d\n", m.failedChunks)

	if m.totalChunks > 0 {
		successRate := float64(m.processedChunks-m.failedChunks) / float64(m.totalChunks) * 100
		log.Printf("ğŸ“ˆ Success Rate: %.2f%%\n", successRate)
	}

	// ì›Œì»¤ ì •ë³´
	log.Printf("ğŸ‘· Max Concurrent Workers: %d\n", m.maxActiveWorkers)

	if len(m.chunkProcessTimes) > 0 {
		avgChunkTime := m.averageDuration(m.chunkProcessTimes)
		minChunkTime := m.minDuration(m.chunkProcessTimes)
		maxChunkTime := m.maxDuration(m.chunkProcessTimes)

		log.Printf("â³ Avg Chunk Processing Time: %s\n", avgChunkTime.Round(time.Millisecond))
		log.Printf("   Min: %s, Max: %s\n", minChunkTime.Round(time.Millisecond), maxChunkTime.Round(time.Millisecond))
	}

	// ë©”ëª¨ë¦¬ ì •ë³´
	if len(m.memorySamplesMB) > 0 {
		avgMem := m.average(m.memorySamplesMB)
		maxMem := m.max(m.memorySamplesMB)
		minMem := m.min(m.memorySamplesMB)

		log.Printf("ğŸ’¾ Memory Usage (MB):\n")
		log.Printf("   Avg: %.2f MB, Min: %.2f MB, Max: %.2f MB\n", avgMem, minMem, maxMem)
	}

	// ê³ ë£¨í‹´ ì •ë³´
	if len(m.cpuSamples) > 0 {
		avgGoroutines := m.average(m.cpuSamples)
		maxGoroutines := m.max(m.cpuSamples)

		log.Printf("ğŸ”„ Goroutines:\n")
		log.Printf("   Avg: %.0f, Max: %.0f\n", avgGoroutines, maxGoroutines)
	}

	// ì²˜ë¦¬ìœ¨ ê³„ì‚°
	if m.totalChunks > 0 && totalDuration.Seconds() > 0 {
		throughput := float64(m.totalChunks) / totalDuration.Seconds()
		log.Printf("âš¡ Throughput: %.2f chunks/sec\n", throughput)
	}

	log.Println(strings.Repeat("=", 60))
}

// PrintProgress : ì‹¤ì‹œê°„ ì§„í–‰ìƒí™© ì¶œë ¥
func (m *ResourceMonitor) PrintProgress() {
	m.mu.Lock()
	defer m.mu.Unlock()

	if m.totalChunks == 0 {
		return
	}

	progress := float64(m.processedChunks) / float64(m.totalChunks) * 100

	var mem runtime.MemStats
	runtime.ReadMemStats(&mem)
	memoryMB := float64(mem.Alloc) / 1024 / 1024

	log.Printf("[Progress] %.1f%% (%d/%d) | Active Workers: %d | Memory: %.2f MB | Goroutines: %d",
		progress,
		m.processedChunks,
		m.totalChunks,
		m.activeWorkers,
		memoryMB,
		runtime.NumGoroutine(),
	)
}

// Helper functions
func (m *ResourceMonitor) average(samples []float64) float64 {
	if len(samples) == 0 {
		return 0
	}
	sum := 0.0
	for _, v := range samples {
		sum += v
	}
	return sum / float64(len(samples))
}

func (m *ResourceMonitor) min(samples []float64) float64 {
	if len(samples) == 0 {
		return 0
	}
	min := samples[0]
	for _, v := range samples {
		if v < min {
			min = v
		}
	}
	return min
}

func (m *ResourceMonitor) max(samples []float64) float64 {
	if len(samples) == 0 {
		return 0
	}
	max := samples[0]
	for _, v := range samples {
		if v > max {
			max = v
		}
	}
	return max
}

func (m *ResourceMonitor) averageDuration(durations []time.Duration) time.Duration {
	if len(durations) == 0 {
		return 0
	}
	sum := time.Duration(0)
	for _, d := range durations {
		sum += d
	}
	return sum / time.Duration(len(durations))
}

func (m *ResourceMonitor) minDuration(durations []time.Duration) time.Duration {
	if len(durations) == 0 {
		return 0
	}
	min := durations[0]
	for _, d := range durations {
		if d < min {
			min = d
		}
	}
	return min
}

func (m *ResourceMonitor) maxDuration(durations []time.Duration) time.Duration {
	if len(durations) == 0 {
		return 0
	}
	max := durations[0]
	for _, d := range durations {
		if d > max {
			max = d
		}
	}
	return max
}
